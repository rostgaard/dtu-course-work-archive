The memory manager of an operating system is, as the name implies, the unit that manages memory. Its job is to keep track of what memory is free and what is not.

\subsection{Basic memory management}
Basic memory management refers to a memory management style where entire programs are kept in memory during execution. The most basic form of this is monoprogramming, where the operating system and one user program share the entire memory. When the program has finished executing the user can select another program to run, which is then loaded into memory and executed. This system was for example used in MS-DOS.\\\\
Monoprogramming has its limitations. One of the most glaring is, of course, the lack of multiprogramming. For multiprogramming to work, multiple programs have to be loaded into memory at the same time. This is done by segregating the memory into partitions. The system has one or more run queues, where arriving jobs will be enqueued. Memory partitioning was particularly useful in batch systems, because it is fairly simple to implement and allowed the CPU to be utilized to its fullest.\\\\
One of the issues with partitioning is programs trying to access absolute memory values, called the relocation problem. In monoprogramming this is never an issue, because we can assume that a program will always have the same starting address. But with partitions, the same program can have a different starting address between two executions. This can be solved by either adding all the absolute memory addresses to the offset of the partition when loading the program, or by having a special register that contains the offset, which is then added to the absolute memory address at execution time.

\subsection{Swapping}
Swapping is the act of copying a process between memory and a disk, without the need of killing the process. It is useful in systems where the memory usage of processes exceeds the memory of the system. If there isn't enough memory available to start a new process, the system will swap an existing process in memory to the disk, so that the new process can execute. Over time this can lead to memory gaps, which can make it difficult to find a contiguous amount of memory without swapping some processes to disk. Memory gaps can be alleviated with memory compaction, but this is can be very CPU intensive.\\\\
Another problem with swapping is that the entire program has to be loaded into the memory for it to be able to execute. What if the system didn't have enough memory to fit the entire program? This is where virtual memory comes into play.

\subsection{Virtual memory}
Virtual memory is based around the principle that every process has its own virtual address space. What it means is that every time a memory location is accessed, the virtual address is translated or mapped to the physical address. This is done by the Memory Management Unit or MMU, which is a hardware device, lying in between the CPU and the memory bus. This means that the CPU uses the virtual address and not the physical address.\\\\
To explain how this works we need to introduce the terms page frames, pages and page tables. \\
A page frame is a block of physical memory. It can vary in size from a couple of bytes up to a gigabyte. A page on the other hand is a block of virtual memory. A page frame and a page are always the same size. One or more page tables keep track of the pages. \\\\
When a process tries to access some memory, the virtual address gets translated to a physical address by the MMU. This is done by splitting the address up into smaller sequences of bits and using them as entries into the page tables. Each page table contains an array of pointers to the next page table. In the case of the AMD64 architecture bits 47 to 39 is the offset into the PML4E page table, which is the top page table. From the PML4E we get the pointer to the PDPE table, which combined with Bits 38 to 30 from the address, gives us the entry into the PDE table. This continues until we reach the page table. The page table has the address of the actual physical frame and combined with the last 12 bits from the virtual address we have the physical address.\\\\
The lowest 12 bits in a page table are used for control and information about the page or page table they are pointing to. There is the present bit, which is used to tell the system if the page is present in physical memory or not. If it isn't, a page fault is generated, which prompts the system to load that specific page into physical memory. This is called paging. There is also a read/write bit which, if set, marks the page as read only. The last bit, bit 63, is the no execute bit. If it is set the page cannot be executed, and is therefore considered data.\\\\
Page translation requires a lot of CPU time. To minimize CPU time spent on translation a Translation Lookaside Buffer or TLB is used. It caches recently accessed pages, which reduces the time the CPU has to spend on page translation. This is explained in \cite{AMD64Manual} \\\\

\subsection{Implementation}
We implemented the function kalloc() and kfree() in the mm.c file. We will first look at the kalloc() function.\\\\
The kalloc function is called with three parameters. The first one is the length of the memory block required, the second is the process id that is requesting the memory, and the third is the flags. The function checks if the requested length is valid. Then it starts searching for enough contiguous memory blocks in the page frame table. Every time it finds a free memory block, it checks if the requested length is reached. When it finds enough free contiguous page frames, it iterates over the found blocks and sets appropriate values to the page frame structs. It then returns the start value of the contiguous blocks. If it doesnâ€™t find enough contiguous blocks it returns error.
The free function is called with one parameter, the start address of the contiguous blocks. The page frame corresponding to that memory address is loaded. It checks if the address is valid. It then iterates over all the memory blocks containing that start address and checks if the free\_is\_allowed flag is set. If it is, it returns an error. If not, they are reset.

\subsection{Test}
The test program runs in a continuous loop first allocating 16 blocks and storing them in an array. When the array is full the program tries to free a block, and then allocate it again. This program ran successfully for a satisfactory amount of time.

\subsection{Reflection}

\subsubsection*{In the system, memory can only be allocated in sizes of multiples (1, 2, 3, ...) of four kilobytes. What are the possible reasons for that?}
This is because the size of a page frame. A page frame is a logical unit used to divide memory into manageable chunks of 4 KB. A page frame is the smallest amount of memory that can be allocated, and since a page frame cannot be divided, 4 KB is the smallest amount

\subsubsection*{In your implementation, memory is maintained using a bitfield structure. What would the differences be if a linked list structure is used? What are the advantages and disadvantages of using a linked list structure?}
The linked list structure would contain segments of memory, where each segment is either a process or a hole. So instead of searching through the entire page frame table for an amount of contiguous pages we would search for a hole that would fit the memory allocation amount. It is more efficient to traverse the linked list where each node can consist of multiple pages, than to search through the entire page frame table. But the code needed to implement the linked list structure would be more complicated, making it more prone to errors. The system call free() would also be slower because it would have to search through the list to find the element.